/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-11-23 04:42:36,322 [INFO] ======================================================================
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:509: ======================================================================
2025-11-23 04:42:36,322 [INFO] QWEN Answer Regeneration with vLLM + RAG
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:510: QWEN Answer Regeneration with vLLM + RAG
2025-11-23 04:42:36,322 [INFO] ======================================================================
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:511: ======================================================================
2025-11-23 04:42:36,322 [INFO] Input directory: /home/himanshu/dev/output/qwen_regenerated
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:512: Input directory: /home/himanshu/dev/output/qwen_regenerated
2025-11-23 04:42:36,322 [INFO] Output directory: /home/himanshu/dev/output/qwen_rag
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:513: Output directory: /home/himanshu/dev/output/qwen_rag
2025-11-23 04:42:36,322 [INFO] QA directory: /home/himanshu/dev/test/data/processed/qa_pairs_individual_components
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:514: QA directory: /home/himanshu/dev/test/data/processed/qa_pairs_individual_components
2025-11-23 04:42:36,322 [INFO] Max tokens: 500
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:515: Max tokens: 500
2025-11-23 04:42:36,322 [INFO] vLLM available: True
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:516: vLLM available: True
2025-11-23 04:42:36,322 [INFO] ChromaDB available: True
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:517: ChromaDB available: True
2025-11-23 04:42:36,322 [INFO] ChromaDB path: /home/himanshu/dev/data/chromadb
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:518: ChromaDB path: /home/himanshu/dev/data/chromadb
2025-11-23 04:42:36,322 [INFO] Test limit: 3
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:519: Test limit: 3
2025-11-23 04:42:36,322 [INFO] ======================================================================
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:520: ======================================================================
2025-11-23 04:42:36,322 [INFO] Initializing model...
[2025-11-23 04:42:36] INFO multimodal_qa_runner_vllm.py:523: Initializing model...
The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
2025-11-23 04:42:37,359 [INFO] Initializing vLLM for ALL questions (text and vision)...
[2025-11-23 04:42:37] INFO multimodal_qa_runner_vllm.py:102: Initializing vLLM for ALL questions (text and vision)...
2025-11-23 04:42:37,360 [INFO] vLLM is REQUIRED - no Transformers fallback available
[2025-11-23 04:42:37] INFO multimodal_qa_runner_vllm.py:103: vLLM is REQUIRED - no Transformers fallback available
2025-11-23 04:42:37,360 [INFO] Environment variables set: VLLM_SKIP_MM_PROFILE=1, SKIP_MM_PROFILE=1
[2025-11-23 04:42:37] INFO multimodal_qa_runner_vllm.py:104: Environment variables set: VLLM_SKIP_MM_PROFILE=1, SKIP_MM_PROFILE=1
2025-11-23 04:42:37,360 [INFO] Starting vLLM initialization (this may take 20-30 seconds)...
[2025-11-23 04:42:37] INFO multimodal_qa_runner_vllm.py:108: Starting vLLM initialization (this may take 20-30 seconds)...
INFO 11-23 04:42:37 [utils.py:253] non-default args: {'trust_remote_code': True, 'dtype': 'float16', 'max_model_len': 8192, 'gpu_memory_utilization': 0.8, 'disable_log_stats': True, 'enforce_eager': True, 'model': '/home/himanshu/dev/models/QWEN_AWQ'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 11-23 04:42:37 [model.py:631] Resolved architecture: Qwen2_5_VLForConditionalGeneration
WARNING 11-23 04:42:37 [model.py:1971] Casting torch.bfloat16 to torch.float16.
INFO 11-23 04:42:37 [model.py:1745] Using max model len 8192
INFO 11-23 04:42:37 [awq_marlin.py:162] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.
INFO 11-23 04:42:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 11-23 04:42:37 [vllm.py:500] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:39 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='/home/himanshu/dev/models/QWEN_AWQ', speculative_config=None, tokenizer='/home/himanshu/dev/models/QWEN_AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/himanshu/dev/models/QWEN_AWQ, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.NONE: 0>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['all'], 'splitting_ops': None, 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.NONE: 0>, 'cudagraph_num_of_warmups': 0, 'cudagraph_capture_sizes': [], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 0, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:40 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.148.0.2:36963 backend=nccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:40 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:44 [gpu_model_runner.py:3259] Starting to load model /home/himanshu/dev/models/QWEN_AWQ...
[1;36m(EngineCore_DP0 pid=261014)[0;0m [2025-11-23 04:42:44] INFO _optional_torch_c_dlpack.py:88: JIT-compiling torch-c-dlpack-ext to cache...
[1;36m(EngineCore_DP0 pid=261014)[0;0m /home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:129: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
[1;36m(EngineCore_DP0 pid=261014)[0;0m We recommend installing via `pip install torch-c-dlpack-ext`
[1;36m(EngineCore_DP0 pid=261014)[0;0m   warnings.warn(
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:47 [vllm.py:500] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=261014)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=261014)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.02s/it]
[1;36m(EngineCore_DP0 pid=261014)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.32s/it]
[1;36m(EngineCore_DP0 pid=261014)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.28s/it]
[1;36m(EngineCore_DP0 pid=261014)[0;0m 
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:49 [default_loader.py:314] Loading weights took 2.62 seconds
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:50 [gpu_model_runner.py:3338] Model loading took 6.5936 GiB memory and 5.697906 seconds
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:42:51 [gpu_model_runner.py:4088] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:43:00 [gpu_worker.py:359] Available KV cache memory: 8.47 GiB
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:43:00 [kv_cache_utils.py:1229] GPU KV cache size: 158,624 tokens
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:43:00 [kv_cache_utils.py:1234] Maximum concurrency for 8,192 tokens per request: 19.36x
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:43:00 [core.py:250] init engine (profile, create kv cache, warmup model) took 10.04 seconds
[1;36m(EngineCore_DP0 pid=261014)[0;0m INFO 11-23 04:43:01 [vllm.py:500] Cudagraph is disabled under eager mode
INFO 11-23 04:43:02 [llm.py:352] Supported tasks: ['generate']
2025-11-23 04:43:02,102 [INFO] vLLM initialized successfully for all question types
[2025-11-23 04:43:02] INFO multimodal_qa_runner_vllm.py:127: vLLM initialized successfully for all question types
2025-11-23 04:43:02,102 [INFO] Initializing ChromaDB search system from /home/himanshu/dev/data/chromadb...
[2025-11-23 04:43:02] INFO multimodal_qa_runner_vllm.py:140: Initializing ChromaDB search system from /home/himanshu/dev/data/chromadb...
[2025-11-23 04:43:02] INFO chromadb_search.py:46: Loading CLIP model...
[2025-11-23 04:43:05] INFO chromadb_search.py:48: CLIP model loaded successfully
[2025-11-23 04:43:05] INFO chromadb_search.py:56: Loading ChromaDB from /home/himanshu/dev/data/chromadb
[2025-11-23 04:43:06] INFO chromadb_search.py:69: ChromaDB collection loaded successfully
[2025-11-23 04:43:06] INFO chromadb_search.py:73: Collection contains 100 documents
2025-11-23 04:43:06,051 [INFO] ChromaDB search system initialized successfully
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:142: ChromaDB search system initialized successfully
2025-11-23 04:43:06,051 [INFO] Model initialized. Using vLLM: True, RAG: True
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:532: Model initialized. Using vLLM: True, RAG: True
2025-11-23 04:43:06,052 [INFO] TEST MODE: Processing 3 files
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:538: TEST MODE: Processing 3 files
2025-11-23 04:43:06,053 [INFO] Total files to process: 3
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:540: Total files to process: 3
2025-11-23 04:43:06,053 [INFO] 
Processing batch 1 (3 files)
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:550: 
Processing batch 1 (3 files)
2025-11-23 04:43:06,053 [INFO] Loading: 100_Nicotine__answers.json (source: 100_Nicotine.json)
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:561: Loading: 100_Nicotine__answers.json (source: 100_Nicotine.json)
2025-11-23 04:43:06,053 [INFO] Loading: 101_Nitric_Acid__answers.json (source: 101_Nitric_Acid.json)
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:561: Loading: 101_Nitric_Acid__answers.json (source: 101_Nitric_Acid.json)
2025-11-23 04:43:06,054 [INFO] Loading: 102_Nitric_Oxide__answers.json (source: 102_Nitric_Oxide.json)
[2025-11-23 04:43:06] INFO multimodal_qa_runner_vllm.py:561: Loading: 102_Nitric_Oxide__answers.json (source: 102_Nitric_Oxide.json)
2025-11-23 04:43:07,422 [INFO]   Batch Q1: Generating 3 vision questions with RAG...
[2025-11-23 04:43:07] INFO multimodal_qa_runner_vllm.py:604:   Batch Q1: Generating 3 vision questions with RAG...
[2025-11-23 04:43:07] INFO chromadb_search.py:148: Image search: '/home/himanshu/dev/tmp/tmpgmt5ylr3.png' (n_results=5)
[2025-11-23 04:43:08] INFO chromadb_search.py:175: Found 5 results
[2025-11-23 04:43:08] INFO chromadb_search.py:148: Image search: '/home/himanshu/dev/tmp/tmp3mqxdllx.png' (n_results=5)
[2025-11-23 04:43:08] INFO chromadb_search.py:175: Found 5 results
[2025-11-23 04:43:08] INFO chromadb_search.py:148: Image search: '/home/himanshu/dev/tmp/tmpvewavzs5.png' (n_results=5)
[2025-11-23 04:43:08] INFO chromadb_search.py:175: Found 5 results
Adding requests:   0%|          | 0/3 [00:00<?, ?it/s]Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:04<00:08,  4.32s/it]Adding requests:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:01,  1.89s/it]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.11s/it]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.56s/it]
Processed prompts:   0%|          | 0/3 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:17<00:34, 17.33s/it, est. speed input: 460.46 toks/s, output: 12.11 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:22<00:10, 10.47s/it, est. speed input: 685.51 toks/s, output: 27.05 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:25<00:00,  6.75s/it, est. speed input: 900.22 toks/s, output: 44.29 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:25<00:00,  6.75s/it, est. speed input: 900.22 toks/s, output: 44.29 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:25<00:00,  8.44s/it, est. speed input: 900.22 toks/s, output: 44.29 toks/s]
2025-11-23 04:43:39,005 [INFO]     Q1[0] done: 30.03s (RAG: True, chunks: 5)
[2025-11-23 04:43:39] INFO multimodal_qa_runner_vllm.py:609:     Q1[0] done: 30.03s (RAG: True, chunks: 5)
2025-11-23 04:43:39,005 [INFO]     Q1[1] done: 30.03s (RAG: True, chunks: 5)
[2025-11-23 04:43:39] INFO multimodal_qa_runner_vllm.py:609:     Q1[1] done: 30.03s (RAG: True, chunks: 5)
2025-11-23 04:43:39,006 [INFO]     Q1[2] done: 30.03s (RAG: True, chunks: 5)
[2025-11-23 04:43:39] INFO multimodal_qa_runner_vllm.py:609:     Q1[2] done: 30.03s (RAG: True, chunks: 5)
2025-11-23 04:43:39,006 [INFO]   Batch Q2-Q4: Generating 9 text questions with RAG...
[2025-11-23 04:43:39] INFO multimodal_qa_runner_vllm.py:635:   Batch Q2-Q4: Generating 9 text questions with RAG...
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'What is the molecular formula of nicotine and what elements does it consist of?' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'Describe the solubility properties of nicotine and the implications for its extraction process.' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'Explain how the historical development and synthesis of nicotine have impacted its applications and uses.' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'What are the primary elements that make up nitric acid, and what is its chemical formula?' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'Discuss the physical state and solubility characteristics of nitric acid.' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'Explain why nitric acid is considered a strong oxidizing agent and describe its reaction with metals.' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'What is the chemical formula and molecular weight of nitric oxide?' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'Explain how nitric oxide is formed in the atmosphere and its role in pollution.' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
[2025-11-23 04:43:39] INFO chromadb_search.py:113: Text search: 'Describe the industrial uses of nitric oxide and its potential hazards.' (n_results=5)
[2025-11-23 04:43:39] INFO chromadb_search.py:137: Found 5 results
Adding requests:   0%|          | 0/9 [00:00<?, ?it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 143.11it/s]
Processed prompts:   0%|          | 0/9 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:  11%|â–ˆ         | 1/9 [00:14<01:56, 14.50s/it, est. speed input: 142.02 toks/s, output: 20.20 toks/s]Processed prompts:  22%|â–ˆâ–ˆâ–       | 2/9 [00:16<00:48,  6.99s/it, est. speed input: 249.81 toks/s, output: 40.02 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 3/9 [00:19<00:31,  5.31s/it, est. speed input: 314.84 toks/s, output: 57.50 toks/s]Processed prompts:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [00:20<00:17,  3.51s/it, est. speed input: 404.67 toks/s, output: 79.99 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:20<00:00,  3.51s/it, est. speed input: 906.58 toks/s, output: 202.84 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:20<00:00,  2.26s/it, est. speed input: 906.58 toks/s, output: 202.84 toks/s]
2025-11-23 04:43:59,804 [INFO]     Q2[0] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q2[0] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,804 [INFO]     Q3[0] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q3[0] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,804 [INFO]     Q4[0] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q4[0] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,804 [INFO]     Q2[1] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q2[1] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,804 [INFO]     Q3[1] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q3[1] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,804 [INFO]     Q4[1] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q4[1] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,805 [INFO]     Q2[2] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q2[2] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,805 [INFO]     Q3[2] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q3[2] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,805 [INFO]     Q4[2] done: 20.40s (RAG: True, chunks: 5)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:642:     Q4[2] done: 20.40s (RAG: True, chunks: 5)
2025-11-23 04:43:59,805 [INFO]   âœ“ Saved 100_Nicotine__answers.json
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:719:   âœ“ Saved 100_Nicotine__answers.json
2025-11-23 04:43:59,806 [INFO]   âœ“ Saved 101_Nitric_Acid__answers.json
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:719:   âœ“ Saved 101_Nitric_Acid__answers.json
2025-11-23 04:43:59,806 [INFO]   âœ“ Saved 102_Nitric_Oxide__answers.json
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:719:   âœ“ Saved 102_Nitric_Oxide__answers.json
2025-11-23 04:43:59,806 [INFO] 
======================================================================
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:749: 
======================================================================
2025-11-23 04:43:59,806 [INFO] REGENERATION SUMMARY
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:750: REGENERATION SUMMARY
2025-11-23 04:43:59,806 [INFO] ======================================================================
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:751: ======================================================================
2025-11-23 04:43:59,807 [INFO] Total files: 3
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:752: Total files: 3
2025-11-23 04:43:59,807 [INFO] Successful: 3
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:753: Successful: 3
2025-11-23 04:43:59,807 [INFO] Failed: 0
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:754: Failed: 0
2025-11-23 04:43:59,807 [INFO] Total time: 53.75s (0.90 min)
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:755: Total time: 53.75s (0.90 min)
2025-11-23 04:43:59,807 [INFO] Average per file: 17.92s
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:756: Average per file: 17.92s
2025-11-23 04:43:59,807 [INFO] vLLM used: True
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:757: vLLM used: True
2025-11-23 04:43:59,807 [INFO] Summary saved to: /home/himanshu/dev/output/qwen_rag/rag_regeneration_summary.json
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:758: Summary saved to: /home/himanshu/dev/output/qwen_rag/rag_regeneration_summary.json
2025-11-23 04:43:59,807 [INFO] ======================================================================
[2025-11-23 04:43:59] INFO multimodal_qa_runner_vllm.py:759: ======================================================================
{
  "total_files": 3,
  "successful": 3,
  "failed": 0,
  "failed_files": [],
  "total_time_s": 53.75344777107239,
  "avg_per_file_s": 17.917815923690796,
  "vllm_used": true,
  "max_tokens": 500,
  "log_file": "/home/himanshu/dev/output/qwen_rag/logs/rag_regeneration_20251123_044236.log"
}
