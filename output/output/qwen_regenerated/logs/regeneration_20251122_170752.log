2025-11-22 17:07:52,681 [INFO] ======================================================================
2025-11-22 17:07:52,681 [INFO] QWEN Answer Regeneration with vLLM Optimization
2025-11-22 17:07:52,681 [INFO] ======================================================================
2025-11-22 17:07:52,682 [INFO] Input directory: /home/himanshu/dev/output/qwen_regenerated
2025-11-22 17:07:52,682 [INFO] QA directory: /home/himanshu/dev/test/data/processed/qa_pairs_individual_components
2025-11-22 17:07:52,682 [INFO] Max tokens: 500
2025-11-22 17:07:52,682 [INFO] vLLM available: True
2025-11-22 17:07:52,682 [INFO] Test limit: 1
2025-11-22 17:07:52,682 [INFO] ======================================================================
2025-11-22 17:07:52,682 [INFO] Initializing model...
2025-11-22 17:08:42,385 [INFO] Model initialized. Using vLLM for ALL questions: True
2025-11-22 17:08:42,386 [INFO] TEST MODE: Processing 1 files
2025-11-22 17:08:42,387 [INFO] Total files to process: 1
2025-11-22 17:08:42,387 [INFO] 
Processing batch 1 (1 files)
2025-11-22 17:08:42,387 [INFO] Processing: 100_Nicotine__answers.json (source: 100_Nicotine.json)
2025-11-22 17:08:42,387 [INFO]   Q1: Generating with image using vLLM...
2025-11-22 17:08:49,401 [ERROR]     Q1 error: You are attempting to load an AWQ model with a device_map that contains a CPU or disk device. This is not supported. Please remove the CPU or disk device from the device_map.
Traceback (most recent call last):
  File "/home/himanshu/dev/code/multimodal_qa_runner_vllm.py", line 116, in generate_with_vision
    outputs = self.vllm_llm.generate([multimodal_prompt], self.vllm_sampling_params)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/entrypoints/llm.py", line 440, in generate
    self._validate_and_add_requests(
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/entrypoints/llm.py", line 1613, in _validate_and_add_requests
    raise e
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/entrypoints/llm.py", line 1601, in _validate_and_add_requests
    request_id = self._add_request(
                 ^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/entrypoints/llm.py", line 1700, in _add_request
    engine_request, tokenization_kwargs = self._process_inputs(
                                          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/entrypoints/llm.py", line 1680, in _process_inputs
    engine_request = self.processor.process_inputs(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/v1/engine/processor.py", line 442, in process_inputs
    self._validate_model_inputs(encoder_inputs, decoder_inputs)
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/v1/engine/processor.py", line 517, in _validate_model_inputs
    self._validate_model_input(decoder_inputs, prompt_type="decoder")
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/vllm/v1/engine/processor.py", line 591, in _validate_model_input
    raise ValueError(
ValueError: The decoder prompt (length 5229) is longer than the maximum model length of 4096. Make sure that `max_model_len` is no smaller than the number of text tokens plus multimodal tokens. For image inputs, the number of image tokens depends on the number of images, and possibly their aspect ratios as well.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/himanshu/dev/code/multimodal_qa_runner_vllm.py", line 401, in regenerate_from_existing_answers
    res1 = wrapper.generate_with_vision(q1, img, max_new_tokens=max_new_tokens)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/multimodal_qa_runner_vllm.py", line 127, in generate_with_vision
    self.transformers_model = AutoModelForImageTextToText.from_pretrained(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/transformers/modeling_utils.py", line 288, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/transformers/modeling_utils.py", line 5162, in from_pretrained
    device_map = _get_device_map(model, device_map, max_memory, hf_quantizer, dtype, keep_in_fp32_regex)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/transformers/modeling_utils.py", line 1473, in _get_device_map
    hf_quantizer.validate_environment(device_map=device_map)
  File "/home/himanshu/dev/code/.venv_phi4_req/lib64/python3.11/site-packages/transformers/quantizers/quantizer_awq.py", line 92, in validate_environment
    raise ValueError(
ValueError: You are attempting to load an AWQ model with a device_map that contains a CPU or disk device. This is not supported. Please remove the CPU or disk device from the device_map.

2025-11-22 17:08:49,405 [INFO]   Q2-Q4: Generating 3 text-only questions...
2025-11-22 17:08:59,533 [INFO]     Q2 done: 10.13s
2025-11-22 17:08:59,533 [INFO]     Q3 done: 10.13s
2025-11-22 17:08:59,533 [INFO]     Q4 done: 10.13s
2025-11-22 17:08:59,534 [INFO]   âœ“ Updated 100_Nicotine__answers.json
2025-11-22 17:08:59,534 [INFO] 
======================================================================
2025-11-22 17:08:59,534 [INFO] REGENERATION SUMMARY
2025-11-22 17:08:59,534 [INFO] ======================================================================
2025-11-22 17:08:59,534 [INFO] Total files: 1
2025-11-22 17:08:59,534 [INFO] Successful: 1
2025-11-22 17:08:59,534 [INFO] Failed: 0
2025-11-22 17:08:59,535 [INFO] Total time: 17.15s (0.29 min)
2025-11-22 17:08:59,535 [INFO] Average per file: 17.15s
2025-11-22 17:08:59,535 [INFO] vLLM used: True
2025-11-22 17:08:59,535 [INFO] Summary saved to: /home/himanshu/dev/output/qwen_regenerated/regeneration_summary.json
2025-11-22 17:08:59,535 [INFO] ======================================================================
